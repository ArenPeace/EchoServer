# 分布式理论专题

## 分布式理论
### CAP
+ Consistency 一致性  
分布式集群中，对同一数据的多个备份的访问是一致的
+ Availability 可用性  
任何请求都能得到正确的响应，不完全保证获取的数据为最新
+ Partition tolerance 分区容错性  
分布式集群中，一部分节点故障，整体仍然可用  

实际效果，跨区跨机房的服务通信失败很正常（丢包、延时），如果不能在有限时间内完成通信，则发生异常，分区不可用。所以，分布式设计中一定会考虑分区容错。
CAP三者不可得兼，舍一存二（PC/PA）。
经典关系数据库的事务一致性、读写实时性、多表关联查询等很多特性在Web2.0被选择性抛弃了。

**CAP和NoSQL**  
NoSQL更注重性能和可扩展性，而非事务机制（经典关系数据库支持ACID强事务性）。
NoSQL仅提供行级别的原子性保证，即对同一`key-value`操作两次，是串行处理，保证ACID。

**Base理论**  
1. 基本可用 Basically Available
允许部分不可用，整体或核心可用
2. 软状态 Soft State
允许不同节点间副本间同步延时，不影响整体可用。
3. 最终一致性 Eventually Consistency
所有副本最终一致。

Base的思想是即使做不到强一致性，也要达到最终一致性。
这样，分布式的多个副本可以异步复制，达到高性能和最终一致。
最终一致性需要保障用户感知的一致性，用户的不一致窗口取决于通信延时/系统负载/副本复制个数。

DNS是典型的最终一致性。

### Paxos
zk集群的zab协议基于paxos，但并没有完全实现。
### Raft

## 分布式管理
### zookeeper

### etcd

## Nosql
### redis集群

## 传统数据库
MPP (Massively Parallel Processing)，即大规模并行处理，将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果(与Hadoop相似)。

Hadoop在处理非结构化和半结构化数据上具备优势，尤其适合海量数据批处理等应用要求。
Hadoop适合海量数据存储查询、批量数据ETL、非机构化数。

MPP适合替代现有关系数据机构下的大数据处理，具有较高的效率。
MPP适合多维度数据自助分析、数据集市等。

简单查询性能相当；HAWQ在处理复杂语句的性能是Hive的三四倍左右。
Hive只支持基准测试99条语句中的66条，而HAWQ支持全部。

## 容器化
### Dokcer
### k8s

## Service Mesh

## 全链路
### ELK

## 分布式ID生成算法
uuid 128太长，zk性能不满足，snowflake需要多研究
### uuid算法
(略)
### snowflake算法
#### 举例
[39bit毫秒数][4bit业务线id][2bit机房id][7bit机器id][5bit预留][7bit毫秒内序号]  
每台服务器绝对递增，全局看只是趋势递增  
必然按msg-id/order-id/worker-id分库分表，取模运算要求ID生成具有“取模随机性",所以毫秒内序列号放最后，保证ID随机  
跨毫秒时，序号总是归0，序号尾为0的比较多，生成的ID取模不均匀，所以不是每次归零，而是归到0-9的随机数。

#### snowflake算法
[1bit不用][41bit时间戳][10bit机器ID][12bit序列号]  
第一比特保留  
时间戳，41比特，从2016年11月1日零点到现在的毫秒数,可以用到2156年，100多年后才会用完  
机器id，10比特，这个机器id每个业务要唯一，机器id获取的策略后面会详述  
序列号，12比特，每台机器每毫秒最多产生4096个id，超过这个数的话会等到下一毫秒  

## 负载均衡算法
web服务器集群，数据库服务器集群，分布式缓存服务集群等集群之前总有负载均衡服务。
云计算/分布式架构，本质也是把后端服务作为计算和存储资源封装到统一入口对外服务。
广泛使用的负载均衡软件：
LVS（linux virtual server)
nginx
haproxy

+ 轮询法，按顺序轮流分配到后端，均衡，不关系后端的存量连接数和系统负载
+ 随机法，按后端列表随机选取，效果接近轮询
+ 源地址哈希，同一IP客户端，总是映射到同一后端
+ 目标地址哈希？
+ 加权轮询，根据后端机器性能和负载，权重不同
+ 加权随机
+ 最小连接数，向最小连接后端分流

## 代理机制
agent/proxy/broker/delegate
主动代理/透传代理/中介代理/委托代理